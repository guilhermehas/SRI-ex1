{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import machado, mac_morpho\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "import enchant\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = []\n",
    "for p, d, f in os.walk(r'machado/machado'):\n",
    "    #print( p,d,f)\n",
    "    if f:\n",
    "        for fileid  in f:\n",
    "            if not fileid.endswith('.txt'):\n",
    "                continue\n",
    "            with open(os.path.join(p,fileid), encoding='iso-8859-1') as g:\n",
    "                textos.append(g.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "swu = stopwords.words('portuguese') + list (string.punctuation)\n",
    "stemmer = PortugueseStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textos = textos[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(texto : str):\n",
    "    return [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "textos = [*map(clean_sentence,textos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = set()\n",
    "for text in textos:\n",
    "    all_words |= set(text)\n",
    "ordered_words = list(sorted(all_words))\n",
    "index_word = dict([(word,i) for i, word in enumerate(ordered_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[0]*len(textos) for _ in range(len(all_words))]\n",
    "for i, document in enumerate(textos):\n",
    "    for word in document:\n",
    "        j = index_word[word]\n",
    "        matrix[j][i] += 1\n",
    "matrix = np.matrix(matrix)\n",
    "binary_matrix = (matrix >= 1)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_from(word, matrix):\n",
    "    clean_word = clean_sentence(word)[0]\n",
    "    if clean_word not in index_word:\n",
    "        return [[0]*matrix.shape[1]]\n",
    "    word_index = index_word[clean_word]\n",
    "    \n",
    "    line = matrix[word_index]\n",
    "    return line/np.sum(line)\n",
    "\n",
    "def binary_frequency(word):\n",
    "    return frequency_from(word,binary_matrix)\n",
    "\n",
    "def word_frequency(word):\n",
    "    return frequency_from(word,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.00487805, 0.        , 0.        , 0.00487805, 0.00487805,\n",
       "         0.        , 0.        , 0.        , 0.00487805, 0.        ,\n",
       "         0.00487805, 0.00487805, 0.        , 0.00487805, 0.        ,\n",
       "         0.        , 0.00487805, 0.00487805, 0.        , 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.        ,\n",
       "         0.00487805, 0.00487805, 0.        , 0.        , 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.        , 0.        ,\n",
       "         0.00487805, 0.        , 0.        , 0.00487805, 0.        ,\n",
       "         0.00487805, 0.        , 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.        , 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.        ,\n",
       "         0.        , 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.        , 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.        , 0.00487805, 0.00487805,\n",
       "         0.        , 0.00487805, 0.        , 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.        , 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.        , 0.00487805, 0.00487805, 0.        , 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.        , 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.        , 0.        , 0.00487805,\n",
       "         0.        , 0.        , 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.00487805, 0.00487805,\n",
       "         0.00487805, 0.        , 0.00487805, 0.00487805, 0.        ,\n",
       "         0.00487805, 0.00487805, 0.00487805, 0.        , 0.00487805,\n",
       "         0.        , 0.00487805, 0.        , 0.        , 0.00487805,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_frequency('agora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.00070497, 0.        , 0.        , 0.00035249, 0.00140994,\n",
       "         0.        , 0.        , 0.        , 0.00035249, 0.        ,\n",
       "         0.00458231, 0.00105746, 0.        , 0.00035249, 0.        ,\n",
       "         0.        , 0.00070497, 0.00140994, 0.        , 0.00105746,\n",
       "         0.00140994, 0.00035249, 0.00035249, 0.00035249, 0.        ,\n",
       "         0.00035249, 0.00070497, 0.        , 0.        , 0.00035249,\n",
       "         0.00035249, 0.00387734, 0.00105746, 0.        , 0.        ,\n",
       "         0.00845964, 0.        , 0.        , 0.00140994, 0.        ,\n",
       "         0.00035249, 0.        , 0.00105746, 0.00176243, 0.00035249,\n",
       "         0.        , 0.00035249, 0.0024674 , 0.00035249, 0.00105746,\n",
       "         0.00070497, 0.00070497, 0.01762425, 0.0024674 , 0.00281988,\n",
       "         0.0024674 , 0.00669722, 0.00352485, 0.00035249, 0.00281988,\n",
       "         0.00070497, 0.00317237, 0.00176243, 0.00105746, 0.        ,\n",
       "         0.        , 0.02220656, 0.00140994, 0.00387734, 0.00387734,\n",
       "         0.00176243, 0.00035249, 0.00211491, 0.00352485, 0.00317237,\n",
       "         0.00176243, 0.00105746, 0.00458231, 0.00352485, 0.00035249,\n",
       "         0.00105746, 0.00105746, 0.00070497, 0.00035249, 0.00035249,\n",
       "         0.00387734, 0.00176243, 0.00211491, 0.00035249, 0.00140994,\n",
       "         0.00070497, 0.        , 0.0024674 , 0.00352485, 0.00035249,\n",
       "         0.00070497, 0.00105746, 0.00281988, 0.00070497, 0.00176243,\n",
       "         0.00458231, 0.00035249, 0.00140994, 0.00070497, 0.00317237,\n",
       "         0.00140994, 0.00140994, 0.00281988, 0.00105746, 0.00105746,\n",
       "         0.00035249, 0.00070497, 0.0024674 , 0.00211491, 0.00176243,\n",
       "         0.00176243, 0.02009165, 0.        , 0.00211491, 0.0024674 ,\n",
       "         0.        , 0.00176243, 0.        , 0.00105746, 0.01550934,\n",
       "         0.00105746, 0.00070497, 0.00176243, 0.00105746, 0.0024674 ,\n",
       "         0.00176243, 0.00281988, 0.        , 0.00176243, 0.00986958,\n",
       "         0.00317237, 0.0024674 , 0.00070497, 0.00070497, 0.00211491,\n",
       "         0.00070497, 0.00105746, 0.00317237, 0.00176243, 0.00035249,\n",
       "         0.00352485, 0.0024674 , 0.0024674 , 0.00176243, 0.00176243,\n",
       "         0.00070497, 0.00458231, 0.00105746, 0.0024674 , 0.00140994,\n",
       "         0.        , 0.00352485, 0.00105746, 0.        , 0.00528728,\n",
       "         0.00176243, 0.00140994, 0.00176243, 0.        , 0.00140994,\n",
       "         0.00281988, 0.00387734, 0.00105746, 0.00070497, 0.00176243,\n",
       "         0.00105746, 0.00211491, 0.00105746, 0.00176243, 0.00035249,\n",
       "         0.00140994, 0.01515686, 0.00035249, 0.00317237, 0.00035249,\n",
       "         0.00140994, 0.01586183, 0.01127952, 0.0024674 , 0.00528728,\n",
       "         0.0140994 , 0.00281988, 0.00422982, 0.00317237, 0.00035249,\n",
       "         0.00140994, 0.00035249, 0.        , 0.        , 0.00035249,\n",
       "         0.        , 0.        , 0.00035249, 0.00035249, 0.04124075,\n",
       "         0.01163201, 0.01832922, 0.04441311, 0.01198449, 0.0422982 ,\n",
       "         0.01762425, 0.02749383, 0.05146281, 0.01515686, 0.01762425,\n",
       "         0.02326401, 0.00281988, 0.00176243, 0.00634473, 0.00317237,\n",
       "         0.00317237, 0.00387734, 0.00070497, 0.00317237, 0.00669722,\n",
       "         0.00458231, 0.00176243, 0.00035249, 0.00810716, 0.01621431,\n",
       "         0.00140994, 0.00845964, 0.00493479, 0.00281988, 0.00035249,\n",
       "         0.02784632, 0.        , 0.11702503, 0.00176243, 0.        ,\n",
       "         0.0165668 , 0.0070497 , 0.00140994, 0.        , 0.00458231,\n",
       "         0.        , 0.00493479, 0.        , 0.        , 0.00035249,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency('agora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfdf(word):\n",
    "    clean_word = clean_sentence(word)[0]\n",
    "    if clean_word not in index_word:\n",
    "        return [[0]*matrix.shape[1]]\n",
    "    word_index = index_word[clean_word]\n",
    "    line = matrix[word_index]\n",
    "    quantity_words_per_doc = matrix.sum(axis=0)\n",
    "    tf = line/quantity_words_per_doc\n",
    "    \n",
    "    freq_word = ((tf > 0)*1).sum()\n",
    "    assert freq_word > 0\n",
    "    df = np.log(matrix.shape[1]/freq_word)\n",
    "    assert df >= 0\n",
    "    return tf*df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5.87186978e-04, 0.00000000e+00, 0.00000000e+00, 1.67729123e-04,\n",
       "         1.03152224e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         1.14956845e-04, 0.00000000e+00, 2.77766347e-04, 5.72138777e-04,\n",
       "         0.00000000e+00, 3.61749121e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "         8.53965137e-04, 2.14559055e-04, 0.00000000e+00, 1.26612192e-03,\n",
       "         2.19202353e-04, 1.10097558e-04, 3.88745324e-04, 3.95491446e-04,\n",
       "         0.00000000e+00, 3.61749121e-04, 3.92384713e-05, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.40571748e-04, 3.01357945e-04, 1.08771945e-04,\n",
       "         1.85663500e-04, 0.00000000e+00, 0.00000000e+00, 2.90783982e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 7.97906157e-04, 0.00000000e+00,\n",
       "         1.64550142e-04, 0.00000000e+00, 2.18961037e-04, 2.73838325e-04,\n",
       "         1.75140785e-04, 0.00000000e+00, 1.00231752e-04, 4.51930205e-04,\n",
       "         3.05908652e-04, 1.35387295e-04, 3.93783060e-04, 1.28124776e-04,\n",
       "         3.56194187e-04, 3.43724993e-04, 3.07326687e-04, 4.18031738e-04,\n",
       "         4.18674109e-04, 3.01457601e-04, 1.39603030e-04, 6.48254424e-04,\n",
       "         4.18648810e-04, 3.30159761e-04, 2.85949744e-04, 2.05086116e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 3.38987666e-04, 1.75689286e-04,\n",
       "         5.99921365e-04, 3.82444150e-04, 5.33728211e-04, 1.82504061e-04,\n",
       "         2.74167755e-04, 4.37221959e-04, 7.17173956e-04, 9.58578111e-04,\n",
       "         1.59557955e-04, 6.75457463e-04, 2.58905931e-04, 6.19509197e-05,\n",
       "         2.80207311e-04, 6.80304316e-04, 6.62626047e-05, 1.42105656e-04,\n",
       "         6.55361455e-05, 2.57516323e-04, 2.14344647e-04, 1.11398100e-03,\n",
       "         2.73345662e-04, 2.14369849e-04, 3.12729943e-04, 0.00000000e+00,\n",
       "         3.78709465e-04, 7.42956629e-04, 8.28734349e-05, 2.12743940e-04,\n",
       "         3.11660781e-04, 3.14754522e-04, 3.44979294e-04, 1.85173224e-04,\n",
       "         4.85096242e-04, 5.90993701e-05, 3.24993862e-04, 1.91112743e-04,\n",
       "         4.36407982e-04, 3.06037024e-04, 3.91457986e-04, 2.99255735e-04,\n",
       "         1.39283084e-04, 1.43900203e-04, 2.43095409e-04, 1.00535736e-04,\n",
       "         4.31457369e-04, 4.82119586e-04, 3.12622697e-04, 2.93688075e-04,\n",
       "         3.84459648e-04, 0.00000000e+00, 3.73865120e-04, 4.09842934e-04,\n",
       "         0.00000000e+00, 2.80236023e-04, 0.00000000e+00, 3.11838467e-04,\n",
       "         2.60789587e-04, 2.18436370e-04, 1.74553908e-04, 1.83754845e-04,\n",
       "         5.58127215e-04, 3.52847912e-04, 3.08914871e-04, 2.96819791e-04,\n",
       "         0.00000000e+00, 2.33565920e-04, 3.72003468e-04, 3.63431675e-04,\n",
       "         3.08795281e-04, 1.19203372e-04, 2.06129516e-04, 4.61768400e-04,\n",
       "         7.68964811e-05, 1.38999916e-04, 1.22454777e-03, 6.53482282e-04,\n",
       "         2.91248493e-04, 7.75506409e-04, 3.13883644e-04, 2.81857530e-04,\n",
       "         3.99127751e-04, 3.76231029e-04, 1.50182501e-04, 2.35347060e-04,\n",
       "         1.72380924e-04, 3.42893847e-04, 3.32551859e-04, 0.00000000e+00,\n",
       "         5.64288322e-04, 1.53814587e-04, 0.00000000e+00, 2.86639068e-04,\n",
       "         4.03187874e-04, 3.67213609e-04, 2.11952519e-04, 0.00000000e+00,\n",
       "         2.55889904e-04, 2.89399296e-04, 2.82868424e-04, 4.22040641e-04,\n",
       "         1.82778503e-04, 3.73762929e-04, 1.58219459e-04, 3.21082871e-04,\n",
       "         1.58816687e-04, 8.48796819e-04, 3.17633374e-04, 4.95775817e-04,\n",
       "         4.37685738e-04, 2.25925101e-04, 5.78390557e-04, 5.26484426e-05,\n",
       "         1.40952112e-04, 2.31170439e-04, 3.84112833e-04, 1.01717614e-04,\n",
       "         2.16157394e-04, 4.19757239e-04, 1.62805275e-04, 1.76326457e-04,\n",
       "         3.14769617e-04, 2.78779139e-04, 1.20942990e-03, 4.73562485e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 4.32041604e-04, 0.00000000e+00,\n",
       "         0.00000000e+00, 2.07655532e-04, 2.48733365e-04, 7.14029193e-04,\n",
       "         2.70373045e-04, 2.75170400e-04, 5.24223362e-04, 4.66015105e-04,\n",
       "         4.51598382e-04, 2.63874659e-04, 3.85061232e-04, 6.71246401e-04,\n",
       "         3.73716605e-04, 2.40739373e-04, 1.62312814e-04, 2.18939126e-04,\n",
       "         1.68441941e-04, 7.63206517e-04, 5.50450859e-04, 2.56630280e-04,\n",
       "         2.50504262e-04, 7.74189201e-05, 4.71115134e-04, 6.76451783e-04,\n",
       "         5.91362335e-04, 8.46432483e-04, 5.55858405e-04, 4.23618124e-04,\n",
       "         6.33970188e-04, 3.39835148e-04, 3.36154057e-04, 1.98283368e-04,\n",
       "         5.79258322e-04, 4.43604761e-04, 3.01597734e-04, 0.00000000e+00,\n",
       "         3.72352607e-04, 2.47383388e-04, 0.00000000e+00, 4.26493787e-04,\n",
       "         2.94875557e-04, 5.24666350e-04, 0.00000000e+00, 3.42214877e-04,\n",
       "         0.00000000e+00, 2.21398369e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "         5.31704744e-05, 0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdf('agora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_normalized(matrix):\n",
    "    log_matrix = np.log(matrix+1)\n",
    "    squared_log_matrix = np.square(log_matrix)\n",
    "    sum_rows = squared_log_matrix.sum(axis=1)\n",
    "    log_normalized_matrix = np.power(np.multiply(squared_log_matrix,np.power(sum_rows, -1)),0.5)\n",
    "    return log_normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.07960309, 0.07960309,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_normalized_matrix = get_log_normalized(matrix)\n",
    "log_normalized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quest√£o 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in textos:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "freq_texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in textos]\n",
    "dictionary = corpora.Dictionary(freq_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_corpus(doc):\n",
    "    new_vec = dictionary.doc2bow(doc.lower().split())\n",
    "    corpus = [dictionary.doc2bow(text) for text in freq_texts]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 4), (1, 1), (2, 1), (3, 2), (4, 2)],\n",
       " [(0, 5), (6, 1), (7, 5), (14, 4), (20, 1)],\n",
       " [(6, 1), (7, 1), (20, 1), (21, 1), (24, 1)],\n",
       " [(6, 1), (7, 18), (13, 1), (16, 1), (20, 1)],\n",
       " [(0, 3), (5, 1), (6, 1), (7, 1), (14, 2)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vet[:5] for vet in to_corpus('agora')[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
